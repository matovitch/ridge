<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Welcome file</title>
  <link rel="stylesheet" href="https://stackedit.io/style.css" />
</head>

<body class="stackedit">
  <div class="stackedit__html"><h1 id="the-ai-tlantic-ridge">The AI-tlantic ridge</h1>
<p>When the mathematician Bernard Dwork proved the rational part of the Weil conjectures in 1960, the famous Alexander Grothendieck, unphased, was already developing the theory of etale cohomology to solve the conjectures completely. It would take <a href="http://www.numdam.org/item/?id=PMIHES_1974__43__273_0">14 more years</a> and many other mathematicians to get there. Jean-Pierre Serre, who was working with Grothendieck at the time, qualified Dwork’s proof of “<a href="https://www.youtube.com/watch?v=pOv-ygSynRI&amp;t=1444s">magnificent but quite finicky</a>”.</p>
<p>In alpinism, you can sometimes face a perilous route to the top like Dwork or follow a long valley and discover some gentle ridges to the summit and many more beside it like Grothendieck. You can be lucky with the hard path, but intelligence is often about being able to recognize you likely won’t succeed without introducing intermediary tools, experiments and computations.</p>
<p>To give another example, if you ask ChatGPT “Can you write and run a Python program to count the number of r(s) in this very question?” it will succeed brilliantly. However, if you ask it to count the number of r(s) in this paragraph without writing or running a program, it will fail most of the time. Note it usually will not think to write a program if you don’t prompt it to.</p>
<p>This week, London-based company DeepMind <a href="https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/">announced the creation of a program able to solve 4 out of 6 problems from the 2024 International Mathematical Olympiad</a>. They have trained Google’s chatbot Gemini to formalize problems for a proof assistant software called Lean and paired it with solver similar to chess (or go) programs (like Leela Zero).</p>
<p>As a side note, and despite the initial analogy relating math and alpinism, I subscribe to the <a href="https://plato.stanford.edu/entries/formalism-mathematics/">formalist</a> philosophy of mathematics and view this activity as a syntactical game that can induce vivid visions and lead you to adopt misguided but useful <a href="https://plato.stanford.edu/entries/platonism-mathematics/">Platonist</a> beliefs. As such, I was quite happy to observe the link of this mathematical solver to classic games like chess and go.</p>
<p>In SF, the future, like the weather, looks often brighter than in London. Californians keep dreaming of larger computers to reach “consciousness” and “superintelligence”. In Paris, the AI startup Mistral is calling its latest chatbot “<a href="https://mistral.ai/news/mistral-large-2407/">large enough</a>” with around 123 billion parameters. You could also argue that the pursuit of scaling laws is environmentally irresponsible or that we will need to <a href="https://situational-awareness.ai/lock-down-the-labs/">regulate these humongous computers as we do nuclear weapons</a>. But I am an optimist, believing big monolithic models will soon reach a dead end. Superintelligence only has a marginal predictive advantage in a chaotic world, and I think we often fear it because we cannot imagine how different from us it may be.</p>
<p>Tighter integration with symbolic programs with e.g. <a href="https://en.wikipedia.org/wiki/Monte_Carlo_tree_search">MCTS</a>, <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">RL</a>, <a href="https://en.wikipedia.org/wiki/Retrieval-augmented_generation">RAG</a> and <a href="https://en.wikipedia.org/wiki/Bayesian_programming">Bayesian programming</a>; the ability to create domain-specific languages and libraries; and the capacity to keep training for harder problems with synthetic data, then being able to decode and translate the results back into natural language: this to me is the future we should aim for. And I believe DeepMind’s result shows we may not need many more <a href="https://en.wikipedia.org/wiki/FLOPS">FLOPS</a>.</p>
<p>Let’s follow the valley without following the Valley.</p>
</div>
</body>

</html>
